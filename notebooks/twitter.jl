### A Pluto.jl notebook ###
# v0.17.7

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local iv = try Base.loaded_modules[Base.PkgId(Base.UUID("6e696c72-6542-2067-7265-42206c756150"), "AbstractPlutoDingetjes")].Bonds.initial_value catch; b -> missing; end
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : iv(el)
        el
    end
end

# ‚ïî‚ïê‚ï° 400cc04e-4784-11eb-11a2-ff8e245cad27
begin
	import Pkg
	Pkg.activate(temp = true)
	Pkg.add([
			Pkg.PackageSpec(name="Chain"),
			Pkg.PackageSpec(name="DataAPI",           version="1"),
			Pkg.PackageSpec(name="DataFrames",        version="1"),
			Pkg.PackageSpec(name="DataFrameMacros"),
			Pkg.PackageSpec(name="CSV",               version="0.8"),
			Pkg.PackageSpec(name="CategoricalArrays", version="0.9"),
			
			])
	
	Pkg.add(["PlutoUI", "Graphs", "GraphMakie", "CairoMakie", "SimpleWeightedGraphs", "FreqTables", "Colors"])

	using SparseArrays, LinearAlgebra
	
	using PlutoUI: FilePicker, TableOfContents
	using Chain: @chain
	import CSV
	using DataAPI: refarray
	using DataFrames: DataFrames, DataFrame, groupby, leftjoin#, #select, select!, combine, transform, transform!, ByRow
	using DataFrameMacros: @transform!, @subset, @combine, @transform, @select
	using CategoricalArrays: CategoricalArrays, categorical
	using Graphs, SimpleWeightedGraphs
	using GraphMakie, CairoMakie, Colors
	using FreqTables
	
	_a_ = 1 # make sure that this is cell #1
	nothing
end

# ‚ïî‚ïê‚ï° 6535e16c-6146-11eb-35c0-31aef62a631c
begin
	# Make sure Python is available - install if necessary
	ENV["PYTHON"] = ""
	Pkg.add(["PyCall", "Conda"])
	Pkg.build("PyCall")
	
	# Install twint (1)
	import Conda
	Conda.pip_interop(true)
	Conda.pip("install", "twint") # it could be so easy ...
	
	# ... but the above command installs twint 2.1.20 which doesn't work any more
	# So we have to download it from github and install it manually.
	
	# One-liner that doesn't always work on Windows
	# run(`$(Conda._pip(Conda.ROOTENV)) install --user --upgrade -e git+https://github.com/twintproject/twint.git@origin/master#egg=twint`)
	
	# Download twint
	import LibGit2
	twint_path = joinpath(@__DIR__(), "twint") # specify where to save twint
	#isdir(twint_path) && rm(twint_path, recursive = true)
	if !isdir(twint_path)
		repo_url = "https://github.com/greimel/twint"
		# fork of 
		#repo_url = "https://github.com/Museum-Barberini/twint"
		#repo_url = "https://github.com/twintproject/twint"
		repo = LibGit2.clone(repo_url, twint_path, branch = "fix/RefreshTokenException") # download twint from github
	end
	
	# Install twint (2)
	Conda.pip("install", "dataclasses") # manually install a dependency because that doesn't work automatically on windows
	dir = pwd() # save current directory, before leaving it
	cd(twint_path) # move to twint folder
	run(`$(Conda._pip(Conda.ROOTENV)) install .`)
	cd(dir) # move back
	
	# Load twint to Julia
	import PyCall
	twint = PyCall.pyimport("twint")
	
	_b_ = _a_ + 1 # make sure this is cell #2
	nothing
end

# ‚ïî‚ïê‚ï° ba5e6141-9927-41e4-8688-cbbb17b8093c
using PlutoUI

# ‚ïî‚ïê‚ï° 8493134e-6183-11eb-0059-6d6ecf0f17bf
md"
`twitter.jl` | **Version 1.7** | *last changed: Feb 6, 2022*"

# ‚ïî‚ïê‚ï° 39feff38-617d-11eb-0682-874b2f747ff8
md"""
Now, it's your turn. Think of an interesting keyword or hashtag. And insert your keyword below. You will see that the graph above will update as soon as you evaluate the new keyword.
"""

# ‚ïî‚ïê‚ï° 8c5a33dc-6174-11eb-397a-43d67c7773e0
keyword = "#econtwitter"

# ‚ïî‚ïê‚ï° 574747d4-617e-11eb-20e7-5760a3a3f3e9
md"""
#### Task 1: Explain your choice (2 points)

üëâ Describe in <150 words why *$(keyword)* is an interesting keyword to search for.
"""

# ‚ïî‚ïê‚ï° cc8bb4e6-617c-11eb-10ed-a316641c78f7
answer1 = md"""
Your answer goes here ...
"""

# ‚ïî‚ïê‚ï° 3ba06884-6481-11eb-20ea-69d7baf86fff
md"""
**NOTE** the word count is done by the function `wordcount` at the very bottom. It is not completely accurate :-). If you are a few words above the limit, that's ok.
"""

# ‚ïî‚ïê‚ï° b2975790-617f-11eb-3dad-ab030c5213ec
md"""
#### Task 2: Analyze the network (5 points)
üëâ Describe the network in terms of the measures that are discussed in lectures 1 and 2. You can look at the notebook **first-networks.jl** and the section *Analyzing the network* for some inspiration.

üëâ Interpret all results that you show.

üëâ Be accurate but concise. Aim at no more than 500 words.

You can spread your answer over multiple cells. Add code and text cells as it suits you.
"""

# ‚ïî‚ïê‚ï° 82b31aea-6180-11eb-0281-c512bdd2f667
answer2_1 = md"""
Start here ...
"""

# ‚ïî‚ïê‚ï° f947607e-647f-11eb-2758-2f931b208406
# some

# ‚ïî‚ïê‚ï° fc185e8e-647f-11eb-3351-910d651cf077
# analysis

# ‚ïî‚ïê‚ï° f5e4f31a-647f-11eb-11c0-87221d14576e
# analyze

# ‚ïî‚ïê‚ï° 05854c34-6480-11eb-021a-07c21ae697ba
# more

# ‚ïî‚ïê‚ï° 0ee478fe-6480-11eb-3d3d-1bc21388754f
answer2_3 = md"""
... write more ... add more cells if you need. If you want to use the word count above, adjust the cell below.
"""

# ‚ïî‚ïê‚ï° 840f84aa-6180-11eb-03bb-71fa9a6e9d17
md"""
#### Task 3: Looking under the hood (3 points)

Now look at section **Constructing a network** of this notebook. Make sure you understand what data are available to us and how we created the network from the data. 

üëâ We want to read your critical thoughts in <250 words. You might tell us about an idea how to generate a different network from the data. Or what twist you would add to our network to make it more interesting. 
"""

# ‚ïî‚ïê‚ï° e96b54dc-6180-11eb-027f-a9db3a83aa99
answer3 = md"""
Your answer goes here ...
"""

# ‚ïî‚ïê‚ï° 3fcf627c-6182-11eb-3a6c-851a6f96bd4a
md"""
#### Before you submit ...

üëâ Make sure you have added your names and your group number [in the cells below](#f021cb3e-6177-11eb-20f6-b5f9c69ed186).

üëâ Make sure that that **all group members proofread** your submission (especially your little essay).

üëâ Go to the very top of the notebook and click on the symbol in the very top-right corner. **Export a static html file** of this notebook for submission. (The source code is embedded in the html file.)
"""

# ‚ïî‚ïê‚ï° 235bcd50-6183-11eb-1272-65c61cfbf961
group_number = 99

# ‚ïî‚ïê‚ï° f021cb3e-6177-11eb-20f6-b5f9c69ed186
group_members = ([
	(firstname = "Ella-Louise", lastname = "Flores"),
	(firstname = "Padraig", 	lastname = "Cope"),
	(firstname = "Christy",  	lastname = "Denton")
	]);

# ‚ïî‚ïê‚ï° 849cd5bc-617b-11eb-12eb-a7f0907fc718
if group_number == 99 || (group_members[1].firstname == "Ella-Louise" && group_members[1].lastname == "Flores")
	md"""
!!! danger "Note!"
    **Before you submit**, please replace the [randomly generated names in this cell](#f021cb3e-6177-11eb-20f6-b5f9c69ed186) by the names of your group and put the [right group number in the cell above.](#235bcd50-6183-11eb-1272-65c61cfbf961).
	"""
end

# ‚ïî‚ïê‚ï° b201cb56-60e3-11eb-302c-4180510aacf8
md"""
# Getting twitter data with `twint`
"""

# ‚ïî‚ïê‚ï° e4dcc0a6-60e3-11eb-2717-5347187c73c0
md"""
First we specify what data we want to have.
"""

# ‚ïî‚ïê‚ï° bdc32cf2-6611-11eb-080c-6fd828280754
md"""
!!! note "Note"
    If you get an error here, ask your group members to send you their `twtter-data.csv` and upload it here. In this case make sure that you still put the right `keyword` above. 

    If you don't have an error message, you don't need to upload a file!
"""

# ‚ïî‚ïê‚ï° 02509edc-6611-11eb-2451-0fa79effbee7
@bind file_data FilePicker()

# ‚ïî‚ïê‚ï° ea8bc558-620d-11eb-24e8-57cd8d41e912
md"""
!!! note "Note"
    If you want to change the parameters of your query you can specify some optional keyword arguments in the cell above. E.g. `tweet_df0 = twitter_data(keyword, language = "dutch")` or `tweet_df0 = twitter_data(keyword, n_tweets = 1000)`.
"""

# ‚ïî‚ïê‚ï° c76895aa-620e-11eb-3da2-b572953e6d34
md"""
If you are curious how the data are downloaded, look at the following function. You shouldn't change these two functions below unless you are absolutely sure what you are doing. The underlying Python package `twint` is very fragile and might hang forever if you don't specify the inputs correctly.
"""

# ‚ïî‚ïê‚ï° 85838053-8aa3-4e56-ae9d-17293937fe4f
"Download tweets that contain `keyword` and save to csv file `filename`"
function download_twitter_data(keyword::String;
							   filename = joinpath(".", "twitter-data.csv"),
							   n_tweets::Int = 500,
							   language = missing,
							   min_likes = 2
							   )
	# Configure twint query object
	c = twint.Config()
	c.Search = keyword
	if !ismissing(language)
		@assert language isa String
		c.Lang = language
	end
	#c.Geo = "52.377956,4.897070,5km"
	c.Limit = n_tweets
	c.Output = filename
	c.Store_csv = true
	c.Min_likes = min_likes
	
	# if file exists, overwrite it
	isfile(filename) && rm(filename)
	twint.run.Search(c)
	
	filename
end

# ‚ïî‚ïê‚ï° 32d55286-620c-11eb-2910-fd3e5b3fd78a
"Download twitter data to csv and load data into a DataFrame"
function twitter_data(file_data, args...; kwargs...)
	# check if file was uploaded using the file picker
	file_uploaded = !isnothing(file_data) 
	
	if file_uploaded
		csv = CSV.File(file_data)
	else
		filename = download_twitter_data(args...; kwargs...)
		csv = CSV.File(filename)
	end
	DataFrame(csv)
end

# ‚ïî‚ïê‚ï° 14e6dece-60dc-11eb-2d5a-275b8c9e382d
tweet_df0 = twitter_data(file_data, keyword)

# ‚ïî‚ïê‚ï° f998e4fc-60e3-11eb-0533-1717bea29668
md"""
# Constructing a network
"""

# ‚ïî‚ïê‚ï° 46021976-60e4-11eb-3797-33b6ff7755d4
md"""
There is more than one way to define a network using this data. One way is to define twitter users to be connected if they use common hashtags in their tweets. Let's ceate such a network.
"""

# ‚ïî‚ïê‚ï° 87f77baa-60e4-11eb-24e2-019e317451f6
md"First select some interesting variables."

# ‚ïî‚ïê‚ï° 97337aec-60e4-11eb-0b15-99ffcf8376fa
md"Then aggregate the list of hashtags for each user."

# ‚ïî‚ïê‚ï° edc6da66-60e4-11eb-1aeb-fb9dbb7ccc88
md"Create a list of edges."

# ‚ïî‚ïê‚ï° 0b70f90c-60e5-11eb-18da-25e3302a74a8
md"""
# Analyzing the network
"""

# ‚ïî‚ïê‚ï° 01e4ac58-60e5-11eb-39f3-b5f613ecee35
md"Create the graph."

# ‚ïî‚ïê‚ï° 4df1e8ae-60ef-11eb-3772-1154f708eecb
md"""
## Highlighting some nodes
"""

# ‚ïî‚ïê‚ï° eea5accc-60db-11eb-3889-c992db2ec8ec
md"""
# Appendix
"""

# ‚ïî‚ïê‚ï° d07dc2ac-67b1-11eb-1bee-c52695fb4f28
md"""
## Package environment
"""

# ‚ïî‚ïê‚ï° 87b7bc86-60df-11eb-3f9f-2375449c77f6
begin
	Base.show(io::IO, ::MIME"text/html", x::CategoricalArrays.CategoricalValue) = print(io, get(x))
end

# ‚ïî‚ïê‚ï° a1d99d9e-60dc-11eb-391c-b52c2e16aedd
md"""
## Install Python and the package `twint`
"""

# ‚ïî‚ïê‚ï° 1f927f3c-60e5-11eb-0304-f1639b68468d
md"""
## Useful functions
"""

# ‚ïî‚ïê‚ï° 620c76e4-60de-11eb-2c82-d364f55fbe4d
function parse_hashtags(hashtags)
	# start from "['r', 'julialang', 'programming']"
	str = replace(hashtags, "'" => '"')
	# get """["r", "julialang", "programming"]"""::String
	vec_of_strings = eval(Meta.parse(str))
	# get ["r", "julialang", "programming"]::Vector{String}
	
	vec_of_strings
end

# ‚ïî‚ïê‚ï° 5401181c-60dd-11eb-0844-9b4b7b35693c
tweet_df = @select(tweet_df0, 
	 # "parse_hashtags" is defined in the appendix
	:hashtags = parse_hashtags(:hashtags),
    :user_id,
	:username = @c(categorical(:username)),
	:language = @c(categorical(:language))
)

# ‚ïî‚ïê‚ï° 9d5c72ca-60df-11eb-262d-6f0803d386f5
user_df = @chain tweet_df begin
	groupby(:username) # group the data by user. Each group consists of all tweets of one user
	@combine(:hashtags = [‚à™(:hashtags...)]) # for each group, take the union (‚à™) of hashtags
end

# ‚ïî‚ïê‚ï° 241b8206-60e0-11eb-08bd-f748c90e49c7
begin
	edge_list = DataFrame(user1 = String[], user2 = String[], common_hashtags = Int[])

	for (i, (user‚ÇÅ, hashtags‚ÇÅ)) in enumerate(eachrow(user_df))
		for (user‚ÇÇ, hashtags‚ÇÇ) in eachrow(user_df[i+1:end,:])
			
			common = hashtags‚ÇÅ ‚à© hashtags‚ÇÇ

			if length(common) > 1
				push!(edge_list, [user‚ÇÅ, user‚ÇÇ, length(common)])
			end
		end
	end

	node_names = edge_list.user1 ‚à™ edge_list.user2 

	@transform!(edge_list, :user1 = @c categorical(:user1; levels = node_names))
	@transform!(edge_list, :user2 = @c categorical(:user2; levels = node_names))
	
	edge_list
end

# ‚ïî‚ïê‚ï° 15ecf0aa-60e2-11eb-1ef4-ebfc215e5ca7
graph = @chain edge_list begin
	sparse(refarray(_.user1), refarray(_.user2), _.common_hashtags, length(node_names), length(node_names))
	Symmetric
	SimpleWeightedGraph
end

# ‚ïî‚ïê‚ï° 41f4f6cc-6173-11eb-104f-69c755afd266
graphplot(graph, node_color="orange")

# ‚ïî‚ïê‚ï° dc41336a-647f-11eb-3ca3-cb3ab8a6a024
# some dummy analysis
begin
	n_edges = ne(graph)
	n_nodes = nv(graph)
end

# ‚ïî‚ïê‚ï° dfc92f56-647f-11eb-3038-15e225cb4d22
answer2_2 = md"""
... Continue here ... The twitter network with $keyword has $n_nodes nodes and $n_edges edges. ...
"""

# ‚ïî‚ïê‚ï° 76c50e74-60f3-11eb-1e25-cdcaeae76c38
node_df = @chain user_df begin
	@subset(:username ‚àà node_names)
	@transform!(:highlighted_nodes = "covid19" ‚àà :hashtags)
	@transform!(:node_color = :highlighted_nodes == true ? colorant"red" : colorant"blue")
end

# ‚ïî‚ïê‚ï° eb9773ea-c66f-4079-b625-9e483413171a
node_df

# ‚ïî‚ïê‚ï° 94e542c2-a3f0-453f-a40c-545a412510b9
graphplot(graph; node_color=node_df.node_color)

# ‚ïî‚ïê‚ï° 91ccdec2-60f3-11eb-2d0e-a59ba5392e65
sum(node_df.highlighted_nodes)

# ‚ïî‚ïê‚ï° 5ceea932-60ef-11eb-3c13-37ddf8e09f6f
let
	all_hashtags = vcat(tweet_df.hashtags...)
	freqs = freqtable(all_hashtags)
	
	df_hashtags = DataFrame(hashtag = names(freqs)[1], freqs = freqs)
	sort!(df_hashtags, :freqs, rev = true)
end

# ‚ïî‚ïê‚ï° c7ed3a0c-faaa-48c1-b442-67e603d99d97
md"""
## Infrastructure
"""

# ‚ïî‚ïê‚ï° af4b0571-e522-4d00-963b-5f1f13adc619
TableOfContents()

# ‚ïî‚ïê‚ï° 31a80c8f-ae90-4dbf-8a3d-e91f316758f2
members = let
	names = map(group_members) do (; firstname, lastname)
		firstname * " " * lastname
	end
	join(names, ", ", " & ")
end

# ‚ïî‚ïê‚ï° da51e362-6176-11eb-15b2-b7bcebc2cbb6
md"""
# Assignment 1: A Twitter Network

*submitted by* **$members** (*group $(group_number)*)

In this assignment you will download a set of *tweets* from social network *Twitter* that share a common keyword. For a start let's use the keyword **$(keyword)**. 

This network consists of twitter users that have used the keyword *$(keyword)* in on of their recent tweets. Two nodes (users) are connected if they have used another hashtag in common. See the plot below.
"""

# ‚ïî‚ïê‚ï° 4b22ab6b-5b3a-47c3-b054-2bc4c4b2f1b0
begin
	hint(text) = Markdown.MD(Markdown.Admonition("hint", "Hint", [text]))
	almost(text) = Markdown.MD(Markdown.Admonition("warning", "Almost there!", [text]))
	still_missing(text=md"Replace `missing` with your answer.") = Markdown.MD(Markdown.Admonition("warning", "Here we go!", [text]))
	keep_working(text=md"The answer is not quite right.") = Markdown.MD(Markdown.Admonition("danger", "Keep working on it!", [text]))
	yays = [md"Great!", md"Yay ‚ù§", md"Great! üéâ", md"Well done!", md"Keep it up!", md"Good job!", md"Awesome!", md"You got the right answer!", md"Let's move on to the next section."]
	correct(text=rand(yays)) = Markdown.MD(Markdown.Admonition("correct", "Got it!", [text]))
	function wordcount(text)
		stripped_text = strip(replace(string(text), r"\s" => " "))
    	words = split(stripped_text, ('-','.',',',':','_','"',';','!'))
    	length(words)
	end
end

# ‚ïî‚ïê‚ï° 09d66db0-617c-11eb-1b92-b3ed2e5f68f6
if keyword == "#econtwitter"
	keep_working(md""" *#econtwitter* is a bit boring. Replace it with a keyword of your choice.""")
else
	correct(md"Go and analyse the tweets on *$(keyword)*!")
end

# ‚ïî‚ïê‚ï° d7046f24-617e-11eb-0571-ebcacb3a39e9
md" ~ $(wordcount(answer1)) words"

# ‚ïî‚ïê‚ï° a36f6492-617f-11eb-2bb8-1ded14d9f438
if answer1 == md"Your answer goes here ..."
	keep_working(md"Place your cursor in the code cell and replace the dummy text, and evaluate the cell.")
elseif wordcount(answer1) > 150
	almost(md"Try to shorten your text a bit, to get below 150 words.")
else
	correct(md"Great, we are looking forward to reading your answer!")
end

# ‚ïî‚ïê‚ï° 163ef7aa-6480-11eb-2ead-e9fb9a35f490
md"*approx. $(sum(wordcount.([answer2_1, answer2_2, answer2_3]))) words*"

# ‚ïî‚ïê‚ï° 0cbb406e-6181-11eb-015d-d582e3a9b175
md"_approx. $(wordcount(answer3)) words_"

# ‚ïî‚ïê‚ï° f1c8a53a-6180-11eb-2e05-179bfab97223
if answer3 == md"Your answer goes here ..."
	keep_working(md"Place your cursor in the code cell and replace the dummy text, and evaluate the cell.")
elseif wordcount(answer3) > 150
	almost(md"Try to shorten your text a bit, to get below 150 words.")
else
	correct(md"Great, we are looking forward to reading your answer!")
end

# ‚ïî‚ïê‚ï° bef961a8-caa3-4360-8b35-d945b7e030d9
md"""
## Acknowledgement
"""

# ‚ïî‚ïê‚ï° 052ab5c3-51a9-43ca-9d95-37f41e283a31
Markdown.MD(
	Markdown.Admonition("warning", "The design of this notebook is based on", 
[md"""
		
_**Computational Thinking**, a live online Julia/Pluto textbook._ [(computationalthinking.mit.edu)](https://computationalthinking.mit.edu)
"""]
	))

# ‚ïî‚ïê‚ï° Cell order:
# ‚ïü‚îÄ8493134e-6183-11eb-0059-6d6ecf0f17bf
# ‚ïü‚îÄ849cd5bc-617b-11eb-12eb-a7f0907fc718
# ‚ïü‚îÄda51e362-6176-11eb-15b2-b7bcebc2cbb6
# ‚ï†‚ïê41f4f6cc-6173-11eb-104f-69c755afd266
# ‚ïü‚îÄ39feff38-617d-11eb-0682-874b2f747ff8
# ‚ï†‚ïê8c5a33dc-6174-11eb-397a-43d67c7773e0
# ‚ïü‚îÄ09d66db0-617c-11eb-1b92-b3ed2e5f68f6
# ‚ïü‚îÄ574747d4-617e-11eb-20e7-5760a3a3f3e9
# ‚ï†‚ïêcc8bb4e6-617c-11eb-10ed-a316641c78f7
# ‚ïü‚îÄd7046f24-617e-11eb-0571-ebcacb3a39e9
# ‚ïü‚îÄ3ba06884-6481-11eb-20ea-69d7baf86fff
# ‚ïü‚îÄa36f6492-617f-11eb-2bb8-1ded14d9f438
# ‚ïü‚îÄb2975790-617f-11eb-3dad-ab030c5213ec
# ‚ï†‚ïê82b31aea-6180-11eb-0281-c512bdd2f667
# ‚ï†‚ïêdc41336a-647f-11eb-3ca3-cb3ab8a6a024
# ‚ï†‚ïêf947607e-647f-11eb-2758-2f931b208406
# ‚ï†‚ïêfc185e8e-647f-11eb-3351-910d651cf077
# ‚ï†‚ïêdfc92f56-647f-11eb-3038-15e225cb4d22
# ‚ï†‚ïêf5e4f31a-647f-11eb-11c0-87221d14576e
# ‚ï†‚ïê05854c34-6480-11eb-021a-07c21ae697ba
# ‚ï†‚ïê0ee478fe-6480-11eb-3d3d-1bc21388754f
# ‚ïü‚îÄ163ef7aa-6480-11eb-2ead-e9fb9a35f490
# ‚ïü‚îÄ840f84aa-6180-11eb-03bb-71fa9a6e9d17
# ‚ï†‚ïêe96b54dc-6180-11eb-027f-a9db3a83aa99
# ‚ïü‚îÄ0cbb406e-6181-11eb-015d-d582e3a9b175
# ‚ïü‚îÄf1c8a53a-6180-11eb-2e05-179bfab97223
# ‚ïü‚îÄ3fcf627c-6182-11eb-3a6c-851a6f96bd4a
# ‚ï†‚ïê235bcd50-6183-11eb-1272-65c61cfbf961
# ‚ï†‚ïêf021cb3e-6177-11eb-20f6-b5f9c69ed186
# ‚ïü‚îÄb201cb56-60e3-11eb-302c-4180510aacf8
# ‚ïü‚îÄe4dcc0a6-60e3-11eb-2717-5347187c73c0
# ‚ïü‚îÄ14e6dece-60dc-11eb-2d5a-275b8c9e382d
# ‚ïü‚îÄbdc32cf2-6611-11eb-080c-6fd828280754
# ‚ï†‚ïê02509edc-6611-11eb-2451-0fa79effbee7
# ‚ïü‚îÄea8bc558-620d-11eb-24e8-57cd8d41e912
# ‚ïü‚îÄc76895aa-620e-11eb-3da2-b572953e6d34
# ‚ï†‚ïê85838053-8aa3-4e56-ae9d-17293937fe4f
# ‚ï†‚ïê32d55286-620c-11eb-2910-fd3e5b3fd78a
# ‚ïü‚îÄf998e4fc-60e3-11eb-0533-1717bea29668
# ‚ïü‚îÄ46021976-60e4-11eb-3797-33b6ff7755d4
# ‚ïü‚îÄ87f77baa-60e4-11eb-24e2-019e317451f6
# ‚ï†‚ïê5401181c-60dd-11eb-0844-9b4b7b35693c
# ‚ïü‚îÄ97337aec-60e4-11eb-0b15-99ffcf8376fa
# ‚ï†‚ïê9d5c72ca-60df-11eb-262d-6f0803d386f5
# ‚ïü‚îÄedc6da66-60e4-11eb-1aeb-fb9dbb7ccc88
# ‚ï†‚ïê241b8206-60e0-11eb-08bd-f748c90e49c7
# ‚ïü‚îÄ0b70f90c-60e5-11eb-18da-25e3302a74a8
# ‚ïü‚îÄ01e4ac58-60e5-11eb-39f3-b5f613ecee35
# ‚ï†‚ïê15ecf0aa-60e2-11eb-1ef4-ebfc215e5ca7
# ‚ïü‚îÄ4df1e8ae-60ef-11eb-3772-1154f708eecb
# ‚ï†‚ïê5ceea932-60ef-11eb-3c13-37ddf8e09f6f
# ‚ï†‚ïê76c50e74-60f3-11eb-1e25-cdcaeae76c38
# ‚ï†‚ïêeb9773ea-c66f-4079-b625-9e483413171a
# ‚ï†‚ïê94e542c2-a3f0-453f-a40c-545a412510b9
# ‚ï†‚ïê91ccdec2-60f3-11eb-2d0e-a59ba5392e65
# ‚ïü‚îÄeea5accc-60db-11eb-3889-c992db2ec8ec
# ‚ïü‚îÄd07dc2ac-67b1-11eb-1bee-c52695fb4f28
# ‚ï†‚ïê400cc04e-4784-11eb-11a2-ff8e245cad27
# ‚ï†‚ïê87b7bc86-60df-11eb-3f9f-2375449c77f6
# ‚ïü‚îÄa1d99d9e-60dc-11eb-391c-b52c2e16aedd
# ‚ï†‚ïê6535e16c-6146-11eb-35c0-31aef62a631c
# ‚ïü‚îÄ1f927f3c-60e5-11eb-0304-f1639b68468d
# ‚ï†‚ïê620c76e4-60de-11eb-2c82-d364f55fbe4d
# ‚ïü‚îÄc7ed3a0c-faaa-48c1-b442-67e603d99d97
# ‚ï†‚ïêba5e6141-9927-41e4-8688-cbbb17b8093c
# ‚ï†‚ïêaf4b0571-e522-4d00-963b-5f1f13adc619
# ‚ï†‚ïê31a80c8f-ae90-4dbf-8a3d-e91f316758f2
# ‚ï†‚ïê4b22ab6b-5b3a-47c3-b054-2bc4c4b2f1b0
# ‚ïü‚îÄbef961a8-caa3-4360-8b35-d945b7e030d9
# ‚ïü‚îÄ052ab5c3-51a9-43ca-9d95-37f41e283a31
